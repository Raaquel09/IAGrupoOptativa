<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Language Agents as Optimizable Graphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2024-02-26">26 Feb 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mingchen</forename><surname>Zhuge</surname></persName>
							<email>mingchen.zhuge@kaust.edu.sa</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">AI Initiative</orgName>
								<orgName type="institution" key="instit2">King Abdullah University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wenyi</forename><surname>Wang</surname></persName>
							<email>wenyi.wang@kaust.edu.sa</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">AI Initiative</orgName>
								<orgName type="institution" key="instit2">King Abdullah University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Louis</forename><surname>Kirsch</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">The Swiss AI Lab IDSIA</orgName>
								<orgName type="institution" key="instit2">USI</orgName>
								<address>
									<region>SUPSI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Francesco</forename><surname>Faccio</surname></persName>
							<email>francesco.faccio@kaust.edu.sa</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">AI Initiative</orgName>
								<orgName type="institution" key="instit2">King Abdullah University of Science and Technology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">The Swiss AI Lab IDSIA</orgName>
								<orgName type="institution" key="instit2">USI</orgName>
								<address>
									<region>SUPSI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dmitrii</forename><surname>Khizbullin</surname></persName>
							<email>dmitrii.khizbullin@kaust.edu.sa</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">AI Initiative</orgName>
								<orgName type="institution" key="instit2">King Abdullah University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">J</forename><surname>Ürgen Schmidhuber</surname></persName>
							<email>juergen.schmidhuber@kaust.edu.sa</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">AI Initiative</orgName>
								<orgName type="institution" key="instit2">King Abdullah University of Science and Technology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">The Swiss AI Lab IDSIA</orgName>
								<orgName type="institution" key="instit2">USI</orgName>
								<address>
									<region>SUPSI</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Language Agents as Optimizable Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-02-26">26 Feb 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">34E194C69FC67943F54E60A1DC68023F</idno>
					<idno type="arXiv">arXiv:2402.16823v1[cs.AI]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.2" ident="GROBID" when="2024-03-06T22:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Various human-designed prompt engineering techniques have been proposed to improve problem solvers based on Large Language Models (LLMs), yielding many disparate code bases. We unify these approaches by describing LLM-based agents as computational graphs. The nodes implement functions to process multimodal data or query LLMs, and the edges describe the information flow between operations. Graphs can be recursively combined into larger composite graphs representing hierarchies of inter-agent collaboration (where edges connect operations of different agents). Our novel automatic graph optimizers (1) refine node-level LLM prompts (node optimization) and (2) improve agent orchestration by changing graph connectivity (edge optimization). Experiments demonstrate that our framework can be used to efficiently develop, integrate, and automatically improve various LLM agents. The code can be found here.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Interest in LLM-powered autonomous problem solvers or agents and their varied applications is continually rising <ref type="bibr" target="#b39">(Wang et al., 2023;</ref><ref type="bibr" target="#b45">Xi et al., 2023)</ref>. However, much work remains to be done to effectively incorporate these agents into a cohesive society and improve their structure automatically.</p><p>Early approaches zero-shot-prompted LLMs or prompted them with few-shot examples <ref type="bibr" target="#b22">(Kojima et al., 2022;</ref><ref type="bibr" target="#b2">Brown et al., 2020)</ref>. Recent methods prompt LLMs in a structured way, such as chain of thought (COT) <ref type="bibr">(Wei et al.,</ref> ⋆ Equal Contribution ♦ Project Engineer Lead 2022), ReAct <ref type="bibr" target="#b49">(Yao et al., 2022)</ref>, tree of thought (TOT) <ref type="bibr" target="#b50">(Yao et al., 2023)</ref>, Reflexion <ref type="bibr" target="#b36">(Shinn et al., 2023)</ref>, and Graph of Thought (GOT) <ref type="bibr" target="#b1">(Besta et al., 2023)</ref>, to improve textbased reasoning. Single agent applications such as Auto-GPT <ref type="bibr" target="#b37">(Torantulino et al., 2023)</ref>, <ref type="bibr">BabyAGI (Nakajima, 2023)</ref>, LangChain <ref type="bibr" target="#b3">(Chase, 2022)</ref>, and Llama-index <ref type="bibr">(Liu, 2022)</ref> utilize LLMs for various functionalities, including tool usage, function calling, and embodied actions. In multi-agent frameworks <ref type="bibr" target="#b52">(Zeng et al., 2022;</ref><ref type="bibr" target="#b53">Zhuge et al., 2023)</ref>, several LLMs take on different roles <ref type="bibr" target="#b23">(Li et al., 2023;</ref><ref type="bibr" target="#b29">Park et al., 2023;</ref><ref type="bibr" target="#b31">Qian et al., 2023;</ref><ref type="bibr" target="#b43">Wu et al., 2023)</ref>, to communicate in natural language and collectively solve a given task. This approach often outperforms single agents, exploiting the specialization <ref type="bibr" target="#b13">(Hong et al., 2023)</ref> of various LLM agents. Unfortunately, it also leads to increasingly different and disparate code bases that require a lot of human engineering to define prompting schemes and the workflow of agents.</p><p>In a "society of mind" (SOM) <ref type="bibr" target="#b27">(Minsky, 1988;</ref><ref type="bibr" target="#b53">Zhuge et al., 2023)</ref>, higher-level intelligence emerges from the combination of simpler and modular cognitive components. Inspired by SOMs, we describe language agent systems through graph representations. Language agents querying LLMs and utilizing external tools are modeled as computational graphs where each node is dedicated to a specific function, while the edges define a topology of how inputs are processed across nodes, mirroring the prompting schemes in prior studies. A swarm is defined as a composite graph, where each subgraph represents a collaborative agent. This creates a deeper hierarchy of intelligence. Agent graphs combine basic LLM operations <ref type="bibr" target="#b17">(Kennedy, 2006;</ref><ref type="bibr" target="#b28">Nepusz &amp; Vicsek, 2013)</ref>, and swarm graphs contain subgraphs representing agents. Approaches such as COT <ref type="bibr" target="#b41">(Wei et al., 2022)</ref>, TOT <ref type="bibr" target="#b50">(Yao et al., 2023)</ref>, and Self-Consistency <ref type="bibr" target="#b40">(Wang et al., 2022)</ref> can be represented by our graphs.</p><p>Our graph representation lends itself to optimization via prompting and evolutionary or reinforcement-learning tech- GPTSwarm is a framework that represents agents as graphs. In this framework, each node represents an operation (e.g., LLM inference or tool use). An agent is a graph composed of these nodes. An edge between two agent graphs characterizes a communication channel; each agent collaborates with others through different channels. When connected, multiple agents form a composite graph with a certain orchestration topology. This graph representation lends itself to optimization of nodes and edges via prompting and evolutionary or reinforcement learning techniques.</p><p>niques, so that agents can improve their communication (or orchestration) patterns. The graph connectivity (adjacency matrices) between agents can self-improve online as a task is being solved or its solution is transferred to another task.</p><p>As a proof-of-concept, we demonstrate how suboptimal agent organization can be overcome and how existing prompting techniques, such as Tree of Thought and Reflexion, can be automatically recombined by optimizing edges in a composite graph. Apart from edge optimization, our framework allows each node in the graph to self-improve by adapting its prompts based on previous input and task feedback.</p><p>Our contributions can be summarized as follows:</p><p>(1) We unify language agent systems by describing them as optimizable computational graphs.</p><p>(2)</p><p>We introduce an open-source framework that allows for constructing arbitrary agent systems by recombining fundamental operations. We describe these engineeringlevel contributions in Appendix A.</p><p>(3) We develop optimization methods for nodes and edges, enabling automatic improvements of agent prompts and inter-agent orchestration.</p><p>(4) We validate our framework on various benchmarks including MMLU, Mini CrossWords, HumanEval, and GAIA, with an emphasis on the benefits of automatic graph optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">GPTSwarm</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Language Agents as Graphs</head><p>Taking inspiration from the society of mind (SOM) <ref type="bibr" target="#b27">(Minsky, 1988;</ref><ref type="bibr" target="#b53">Zhuge et al., 2023)</ref>, we propose to organize intelligence within a modular and hierarchical framework. This framework consists of nodes, graphs, and composite graphs, with each component playing a specific role. A node represents a fundamental operation that includes, but is not limited to, LLM inference, tool use, function calls, and various embodied actions. An agent, conceptualized as a graph, consists of multiple nodes that form a coherent functional entity. A swarm, or composite graph, represents a complex system of agents where the collective capabilities of this system may exceed those of individual agents. Finally, the edges within an agent define its execution topology, while the edges between agents establish collaboration and communication among them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Graph Definition</head><p>Single language agent as a graph. We model a language agent as a directed computational graph G, defined by a tuple (N, E, F, o), where N is a set of computational nodes, E ⊂ N ×N is a set of directed edges, F = {f n } n∈N is a set of computational routines and o ∈ N is an output node. The set of predecessors of node n is denoted by pre(n). In this paper, we focus on directed acyclic graphs (DAGs). Given an input x, a graph G iteratively executes its nodes according to their topological order. Each node n ∈ N receives as input x and the output z n from its predecessor nodes. In this work, inputs and outputs are strings in natural language, but may take on other data types more generally. Node n applies the computational routine f n (z n , x) and sends the output to its successor nodes. The graph output, denoted ŷ = G(x), is the output f o (z o , x) from the output node o.</p><p>Note that in a DAG, some nodes will not have predecessors.</p><p>For such nodes, the context z will be empty. This graph execution procedure is summarized in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Graph Execution</head><p>Require: Computational graph G = (N, E, F, o), input x, empty context z for each node without predecessors.</p><p>for n in TopologicalSort(N ) do</p><formula xml:id="formula_0">z n ← {f n (z v , x) : v ∈ pre(n)} end for Ensure: f o (z o , x)</formula><p>In the context of language agents, for example, the input x may correspond to a question in natural language. Each node processes the input x and context information z from its predecessor nodes by applying a computational routine f . Examples of routines include LLM queries with input data from other agents, instructions to generate prompts for web searches that gather task-related information, or tool usage. Although our formalization specifies that the input x is given to each node, in practice, many routines might be designed to ignore the input and operate solely in the context provided by the predecessor nodes. Finally, the output provided by the output node corresponds to the answer to the input question or, more generally, to the solution of the input task.</p><p>Swarm of language agents as a composite graph. Given a set of K language agents, each represented by a computational graph</p><formula xml:id="formula_1">{G k = (N k , E k , F k , o k )} K k=1</formula><p>, one can compose these agents to achieve high performance in specific tasks. Let N ′ = ∪ k N k represent the union of the nodes of the agents, E ′ = ∪ k E k be the union of the edges of the agents, F ′ = ∪ k F k be the union of the computational routines of the agents, and o ′ ∈ ∪ k {o k } be the output node for the composite graph. Consider a selection of edges E ⊂ ∪ i̸ =j N i ×N j that describe a set of connections between nodes from different agents. We define the composite graph representing the swarm of agents as</p><formula xml:id="formula_2">G E = (N ′ , E E , F ′ , o ′ ),</formula><p>where E E = E ′ ∪ E is the union of the edges of the agents and the new edges connecting them. Composite graphs are restricted to DAGs. The composite graph G E can be executed as described in Algorithm 1. In a swarm of language agents, the newly specified edges represent communication channels between agents. In the following sections, we explore how to optimize such a computational graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Edge Optimization</head><p>Given a task τ and its associated utility function u τ that maps the candidate graphs to real numbers, we formulate an optimization problem about the choice of additional edges. The goal is to identify the edges that connect various language agents in a swarm, maximizing the utility. This process involves determining the most effective patterns of communication and information exchange among agents for the task at hand. We consider a set of potential edges {e i } d i=1 = E, which leads to 2 d possible edge configurations, symbolized as E ∈ {0, 1} d . We further restrict the search space to only consider composite graphs that are DAGs. Formally, optimization of the composite graph of language agents is achieved by solving the problem max E u τ (G E ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1.">PROBLEM REFORMULATION</head><p>DAG optimization through pruning of nodes and edges was already present in the first work on "deep learning" with deep feedforward networks <ref type="bibr" target="#b15">(Ivakhnenko et al., 1965;</ref><ref type="bibr" target="#b16">Ivakhnenko, 1968)</ref>. Due to the combinatorial complexity induced by DAGs, recent studies have increasingly focused on the continuous optimization approach <ref type="bibr" target="#b38">(Vowels et al., 2022)</ref>. This is particularly relevant in scenarios where most node executions require one or more queries to LLMs for moderate-scale applications. Moreover, the utility function is typically non-differentiable due to the tokenization of LLMs, and this remains true even when a differentiable DAG sampling technique is employed. Therefore, we reformulate our edge optimization as a continuous optimization problem. Instead of optimizing in a discrete space, our approach is to optimize over a continuum of probabilistic distributions, each representing a distribution over the feasible DAGs. Formally, rather than solving the maximum utility function arg max E u τ (G E ), we propose solving</p><formula xml:id="formula_3">arg max θ∈Θ E G ′ ∼D θ [u τ (G ′ )],<label>(1)</label></formula><p>where D θ is a parameterized distribution and Θ represents a feasible set of real-valued parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.">SOLUTION PARAMETERIZATION</head><p>A straightforward way to define a parameterized probabilistic distribution over DAGs with fixed nodes N and required edges E is to assign a real-valued parameter θ i ∈ R to each potential edge e i . Let θ = [θ 1 ; θ 2 ; . . .</p><formula xml:id="formula_4">; θ d ] ∈ [0, 1] d . The probability of G ′ = G E for G ′ ∼ D θ is d i=1 θ i if (N, E ∪ ({e j } i−1 j=1 ∩ E) ∪ {e i }) is a DAG, 0 otherwise.</formula><p>A sampling method that realizes this distribution is first to initialize a graph G ′ ← (N, E). Then, iteratively sample whether to include edge e i in G ′ for all i's. If including e i causes a cycle in current G ′ , then the edge would not be included. Otherwise, add the edge to G ′ with probability θ i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3.">OPTIMIZATION ALGORITHM</head><p>To optimize the objective function (Equation ( <ref type="formula" target="#formula_3">1</ref>)), we apply the REINFORCE algorithm <ref type="bibr" target="#b42">(Williams, 1992)</ref> by applying a gradient ascent variant (e.g., Adam <ref type="bibr" target="#b19">(Kingma &amp; Ba, 2014)</ref>) with an unbiased gradient estimation:</p><formula xml:id="formula_5">∇ θ EG E ∼D θ [uτ (GE )] ≈ 1 M M i=1 ûτ (Gi)∇ θ log(p θ (Gi)),<label>(2)</label></formula><p>where G 1 , G 2 , . . . , G N ∼ D θ are mutually independent and ûτ (G i ) is an independent unbiased estimate of u τ (G i ) for all i and some M ∈ N. Algorithm 2 describes the optimization algorithm with vanilla gradient ascent.</p><p>Algorithm 2 Edge Optimization with REINFORCE Require: A parameterized probabilistic distribution over computation graphs D θ , an unbiased utility estimator ûτ (•), and a learning rate α.</p><formula xml:id="formula_6">Initialize θ ∈ R d . while terminate condition not met do Sample G i ∼ D θ for i = 1, 2, . . . , M . Update θ ← θ + α M M i=1 ûτ (G i )∇ θ log(p θ (G i )). end while</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Node Optimization</head><p>In our framework, each node implements a fundamental operation, such as querying an LLM, using a tool, calling an API, etc. In a language agent, most of these operations involve prompting an LLM once or several times. Optimizing the prompts of these nodes is crucial for improving the system's overall performance.</p><p>Unlike many other works on prompt optimization, which optimize a single global prompt (e.g., <ref type="bibr" target="#b48">Yang et al., 2023;</ref><ref type="bibr" target="#b30">Pryzant et al., 2023;</ref><ref type="bibr" target="#b7">Deng et al., 2022)</ref>, our node optimization problem naturally involves several operations where each of them consists of a node-level prompt. In our case, the optimization problem is more complex due to prompts affecting how other prompts operate on connected nodes. At the same time, our graph representation leads to a separation of concerns where each node has a specific purpose with its own associated prompt. Due to this separation of concerns, we hypothesize that, for every optimization step, it is sufficient to update each node-level prompt individually, assuming that all other prompts are fixed.</p><p>Consider a parameterized computational graph G P = (N, E, F P , o), where F P = {f pn n } are computational routines, each parameterized by a prompt p n to be optimized for all n ∈ N . To enable effective node optimization, we also require a natural language description of the intended function for each routine f pn n ∈ F denoted by d n . For example, a suitable description for a node designed to write Python programs would be "a Python code generator". Here, existing prompt optimization methods, such as OPRO <ref type="bibr" target="#b48">(Yang et al., 2023)</ref>, can be described as a function I that iteratively maps a prompt, a function description, and a set of node input-output pairs (which may include annotations such as a quality measure for each pair) to an improved prompt. For example, I could take a prompt such as "generate Python code", a description "a Python code generator", and an input-output pair "Input: evaluate two divided by one as an integer. Output: 2 / 1", where the output yields 1.0 as the result of execution. A prompt optimization method would return an improved prompt "generate Python code and pay attention to data types".</p><p>Formally, our method begins by initializing an empty history set, denoted h n , one for each node n ∈ N . The process then proceeds iteratively: first, the graph G P (x) is executed using a randomly sampled input x following Algorithm 1. Subsequently, for each node, a tuple consisting of the input to the node (z n , x), where z n is the context vector that includes the outputs of the predecessor nodes, and the node's own output f pn n (z n , x), is added to the node's history h n . The final step involves updating the node prompts. This is done by applying I to the node's updated history, its current prompt, and its function description, resulting in an improved prompt I(h n , p n , d n ). This iterative process, described in Algorithm 3, continuously improves the operations of the nodes in the entire graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3 Node Optimization</head><p>Require: A parameterized graph G P = (N, E, F P , o), natural language function descriptions D = {d n } n∈N , and a distribution of inputs D X .</p><p>Initialize</p><formula xml:id="formula_7">p n for all n ∈ N . Initialize h n ← ∅ for all n ∈ N . while terminate condition not met do Sample input x ∼ D X . y ← G P (x) following Algorithm 1. h n ← h n ∪ {((z n , x), f pn n (z n , x))} for all n ∈ N . p n ← I(h n , p n , d n ), for all n ∈ N . end while</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">General Applicability</head><p>Frameworks such as AutoGPT <ref type="bibr" target="#b37">(Torantulino et al., 2023)</ref> and LangChain <ref type="bibr" target="#b3">(Chase, 2022)</ref> have set a standard for flexibility and reusability in various language-based tasks. Our framework, GPTSwarm, introduces a graph-based design of agents and swarms. This design further simplifies the reuse of modular components (nodes &amp; agents) and the integration of such modules. For instance, GPTSwarm supports 41 types of file analysis, web search (e.g., Google Search), and index-based memory. By offering a wide range of modules, our framework makes it easier to implement various language agent systems. See Section 3.4 for further details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">MMLU</head><p>Motivation: In our first experiments, we demonstrate that edge optimization effectively filters adversarial agents from a swarm, mirroring a scenario in multi-agent systems where some agents are detrimental rather than beneficial. Ideally, optimization would automatically eliminate harmful agents. We conducted this experiment using the 4-choice MMLU general knowledge question answering dataset, as detailed by <ref type="bibr" target="#b12">Hendrycks et al. (2021b;</ref><ref type="bibr">a)</ref>. Our setup involves initializing a swarm consisting of k Input-Output (IO) agents and k adversarial agents, following the terminology by <ref type="bibr" target="#b1">Besta et al. (2023)</ref>. The IO agents query an LLM and relay the LLM's responses directly. In contrast, adversarial agents are deliberately programmed to manipulate the LLM to provide incorrect answers. The collective decision on the final answer is made through majority voting, bypassing any additional LLM query that could introduce corrective intelligence against adversarial influence. We benchmark the performance of a single IO agent as our baseline. An effective optimization is expected to elevate the swarm's performance on the MMLU dataset to match this baseline level.</p><p>Analysis: In Figure <ref type="figure" target="#fig_1">2</ref>, we present the comparative performance scores of different swarm configurations: the baseline, the graph formed by sequentially including edges that do not create loops (denoted as the 'full graph'), a randomly connected swarm sampled from the initial distribution D θ with θ = 0.5, and the optimized swarm. These scores are based on an evaluation of 10% of the MMLU validation set, which consists of 153 questions. The edge optimiza- We observe that the parameters first change chaotically. However, after iteration 6, the parameters change almost monotonically.</p><p>tion process uses REINFORCE (Alg. 2) over 200 iterations. Each iteration assesses four graph samples, each on a specific problem sourced from the MMLU dev set. Throughout these experiments, we employed GPT-4-Turbo, with the token sampling temperature fixed at 0.2. Figure <ref type="figure" target="#fig_9">9</ref> demonstrates how the optimized swarm score aligns asymptotically with that of the baseline. Table <ref type="table" target="#tab_3">3</ref> compiles the key statistics and findings of these experiments. The findings indicate that our approach successfully safeguards a swarm against harmful adversaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Mini Crosswords</head><p>Motivation: This section investigates to what extent edge optimization can improve the performance of standard agents from the literature. We conduct our evaluation on the Mini Crosswords dataset<ref type="foot" target="#foot_0">1</ref> . A subset of 20 problems is used to optimize and evaluate our methods, in agreement with previous studies <ref type="bibr" target="#b50">(Yao et al., 2023;</ref><ref type="bibr" target="#b35">Sel et al., 2023)</ref>. The choice of Mini Crosswords for this analysis is strategic, as it highlights how the algorithmic structure of the solvers, such as the tree search employed by TOT, significantly influences their performance <ref type="bibr" target="#b50">(Yao et al., 2023)</ref>. Our hypothesis is that edge connections can meaningfully determine the algorithmic structure. Through edge optimization, we anticipate the automatic discovery and implementation of high-performance algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis:</head><p>In our experiments, we explore the performance of swarms of three distinct agents. The first agent, which implements the TOT approach, iteratively branches over candidate solutions provided by an LLM, processing one word at each step. The second agent is based on the Reflexion method <ref type="bibr" target="#b36">(Shinn et al., 2023)</ref>. This agent first proposes a solution through a greedy approach and then creates an al-ternative solution informed by feedback from a critic, which is based on an LLM analysis of the initial solution. The third agent we examine is a Chain of Thought (COT) agent consisting of three nodes. Each node within the COT performs an internal brute-force search to select the optimal subset of candidates generated by the LLM for the current state, scored by the LLM. The agent or swarm then returns all the solutions generated by their output node.</p><p>For the utility function, we choose the best of all the graphreturned solutions according to the number of words correctly filled (i.e., best state word accuracy) as done by <ref type="bibr" target="#b50">Yao et al. (2023)</ref>. During the evaluation, we average over 20 graph samples from the graph distribution, each evaluated on a unique question randomly sampled from the dataset.</p><p>We optimize our composite graph of agents using the RE-INFORCE (Alg. 2), setting the initial edge probability at θ = 10% and the learning rate at α = 0.4. For each iteration, the gradient is estimated according to equation ( <ref type="formula" target="#formula_5">2</ref>) by sampling M = 20 graphs, each evaluated on a crossword problem. For cost-effectiveness, we optimize and evaluate graphs with the GPT-3.5-Turbo language model, where the temperature is set to zero. Figure <ref type="figure" target="#fig_2">3</ref> visualizes the evolution of probability parameters in the form of adjacency-like matrices over ten iterations. We observe that the parameters first change chaotically. However, after iteration 6, the parameters change almost monotonically.</p><p>We follow Alg. 2 to optimize the objective in Equation <ref type="formula" target="#formula_3">1</ref>, achieving an average accuracy of 0.575(±0.0275) after ten iterations (we report the average over 3 runs and the standard error). This surpasses the initial distribution's score of 0.465(±0.0509). Furthermore, we evaluate the best-ofthree performance by aggregating the top results from each problem across the three agents, which yields an accuracy of 0.320(±0.0415).</p><p>Note that denser graphs are likely to require more computational resources. To verify that the improvements of our method are not solely due to an increase in the number of edges and therefore a larger computational budget, we compare it with a distribution with all parameters set to θ = 12.5%. This value reflects the average number of edges in the learned distribution, determined by sampling 1000 graphs from each run's resulting distribution. The expected number of edges for both the learned distribution and the 0.125 parameter-valued distribution are approximately 29.71(±1.74) and 29.68(±0.10), respectively. Despite the similarity in the edge count, the 0.125 parameter-valued distribution achieves an accuracy of 0.510(±0.0552), allowing us to attribute the improvements to factors beyond the mere edge density.</p><p>Furthermore, we evaluate one of our final optimized distributions (randomly selected) with the GPT-4-Turbo language model<ref type="foot" target="#foot_1">2</ref> . It achieves an accuracy of 0.800(±0.0616), significantly exceeding the previous state-of-the-art performance of 0.675 <ref type="bibr" target="#b50">(Yao et al., 2023)</ref>. All reported metrics are summarized in Figure <ref type="figure" target="#fig_3">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">HumanEval</head><p>Motivation: In the previous experiments on MMLU (math problems) and Mini Crosswords (open-ended puzzles) we have validated the utility of optimizing graph edges. In this section, we test the HumanEval dataset <ref type="bibr" target="#b5">(Chen et al., 2021)</ref>, which is known to be sensitive to prompt design. Previous research involved manually crafting prompts <ref type="bibr" target="#b36">(Shinn et al., 2023;</ref><ref type="bibr" target="#b13">Hong et al., 2023)</ref> and achieved impressive performance. In contrast, here, we explore how node-based optimization can simplify this process. We employ an online learning setting, continuously optimizing without restarting.</p><p>Analysis: In this section, we optimize the prompts of a ReAct-style <ref type="bibr" target="#b49">(Yao et al., 2022)</ref>  Altering the instruction prompts rarely improved the results, possibly due to the limited sophistication of our current meta-prompts compared to OPRO <ref type="bibr" target="#b48">(Yang et al., 2023)</ref> and PromptBreeder <ref type="bibr" target="#b9">(Fernando et al., 2023)</ref>. However, selectively incorporating previously executed input-output pairs, The GAIA benchmark <ref type="bibr" target="#b26">(Mialon et al., 2023)</ref> tests for many of these capabilities by including questions that require several of these tools for successful completion.</p><p>Table <ref type="table">1</ref>. Performance on the GAIA Benchmark <ref type="bibr" target="#b26">(Mialon et al., 2023)</ref>. Using our framework, we demonstrate significant improvements across several levels of difficulty. The 'GPT-4 with plugins' baseline is less significant since it involves the manual selection of the appropriate tools per question. We report the mean and standard deviation across 5 runs. which correspond to successful program generations of the graph, as demonstration examples in the context of the nodes, increases the pass@1 accuracy from 77% to 89%. We select input-output pairs by assessing their effectiveness as demonstration examples, particularly in improving the node operation applied to the node's ten most recent inputs.</p><p>To evaluate a node operation, we determine if the generated program successfully solves the unit tests provided in the input problem statement. For more details on the node optimizer, please refer to Appendix D.3.1. We hypothesize that the performance could be further improved with more sophisticated (meta-)prompts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">GAIA</head><p>Motivation: GAIA is a benchmark specifically designed for testing the generality of AI assistants focusing on realworld questions <ref type="bibr" target="#b26">(Mialon et al., 2023)</ref>. Abilities required to answer GAIA questions include reasoning, multi-modality processing, web browsing, and other tool use. Although conceptually straightforward for humans, these questions present significant challenges for current AI systems.</p><p>Using this benchmark, we evaluate the general applicability of our framework. We construct swarms with multiple agents of the same type and employ self-consistency (a prompt-based majority vote) for the final decision <ref type="bibr" target="#b40">(Wang et al., 2022)</ref>. We also experimented with adding different types of agents to the swarm and using prompt-based best answer selection. The results indicate that prompt-based self-consistency yields the best performance. Note that these experiments are meant to demonstrate the generic capabilities of our modular framework and include neither edge-based nor node-level optimization, which is left for future work.</p><p>Analysis: Table <ref type="table">1</ref> shows the results of our swarm with seven TOT agents and the self-consistency strategy for the final decision. We compare the performance of the GPT-Series <ref type="bibr" target="#b0">(Achiam et al., 2023)</ref> with plugins and Auto-GPT <ref type="bibr" target="#b37">(Torantulino et al., 2023)</ref> performance as reported by <ref type="bibr" target="#b26">Mialon et al. (2023)</ref>. Our methods significantly outperform these baselines.</p><p>Table <ref type="table">2</ref> presents a more comprehensive set of results. We experiment with varying numbers of agents and different node operations, such as different tool uses. Our observations indicate that the time requirement of a swarm grows approximately linearly with the number of agents. Despite the increased computational time, incorporating more agents notably improves the overall performance of the system. We also found that a greater variety of node operations leads to better performance. As illustrated in Figure <ref type="figure" target="#fig_4">5</ref>, web browsing is required for 43.9% of the tasks. Our current implementation accesses the Internet by only downloading materials directly from the URLs provided in the problem statement or querying a Google search<ref type="foot" target="#foot_2">3</ref> without further website navigation. Therefore, we believe that enhancing web capabilities would further increase performance significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">LLM-based Autonomous Agents</head><p>Current works on LLM-based autonomous agents or language agents vary in focus. Methods such as Chain of Thought <ref type="bibr" target="#b41">(Wei et al., 2022)</ref>, ReAct <ref type="bibr" target="#b49">(Yao et al., 2022)</ref>, Reflexion <ref type="bibr" target="#b36">(Shinn et al., 2023)</ref>, and Tree of Thought (ToT) improve prompt strategies and structure to improve reasoning capabilities. Single LLM agent frameworks such as Auto-GPT <ref type="bibr" target="#b10">(Gravitas, 2023)</ref>, LangChain <ref type="bibr" target="#b3">(Chase, 2022)</ref>, LlamaIndex <ref type="bibr">(Liu, 2022)</ref>, and XAgent (XAgent <ref type="bibr" target="#b44">Team, 2023)</ref> showcase problem solving through various external functions and tools. In the space of LLM-based multiagent systems <ref type="bibr" target="#b46">(Xie et al., 2023;</ref><ref type="bibr" target="#b4">Chen et al., 2023a;</ref><ref type="bibr">b)</ref>, NLSOMs <ref type="bibr" target="#b53">(Zhuge et al., 2023)</ref> employ various social structures for task-specific applications (inspired by SOMs <ref type="bibr" target="#b27">(Minsky, 1988</ref>)), without</p><p>Table <ref type="table">2</ref>. Ablations on the GAIA benchmark (Level 1 validation set) <ref type="bibr" target="#b26">(Mialon et al., 2023)</ref>. DA = DirectAnswer, GQ = GenerateQuery, WS = WebSearch, FA = FileAnalyzer, CA = ComebineAnswer. ' ' indicates the presence of a specific feature in the corresponding framework, ' ' its absence. Each type of experiment is run five times to record the mean, standard deviation, and best run (marked as Best). Self-Consistency describes prompt-based self-consistency <ref type="bibr" target="#b40">(Wang et al., 2022)</ref> exploring optimization over the social structure of agents. CAMEL <ref type="bibr" target="#b23">(Li et al., 2023)</ref>, Generalist Agents <ref type="bibr" target="#b29">(Park et al., 2023)</ref>, ChatDev <ref type="bibr" target="#b31">(Qian et al., 2023)</ref>, and AutoGen <ref type="bibr" target="#b43">(Wu et al., 2023)</ref> focus on role-play communication, but struggle with hallucinations. MetaGPT <ref type="bibr" target="#b13">(Hong et al., 2023)</ref> introduces standard operating procedures for better role definition and communication, making the collaboration between agents more effective. In contrast to these frameworks, we automatically optimize nodes and edges in a self-organizing society of agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Language Agents with Graphs</head><p>Besta et al. ( <ref type="formula">2023</ref>) introduced LLM-based problem-solving with graphs; however, the approach only encompasses LLM prompting schemes without modeling other fundamental capabilities of language agents, such as use of external tools. LangGraph (langchain ai, 2024), on the other hand, is a concurrent open-source framework that focuses on building multi-actor state LLM applications through possibly cyclical operations. However, its practical applicability has not yet been systematically studied. Unlike previous studies, our approach emphasizes the development of hierarchical intelligence, as discussed by <ref type="bibr" target="#b27">Minsky (1988)</ref> and <ref type="bibr" target="#b17">Kennedy (2006)</ref>, through the construction of agent graphs and the composition of multiple graphs into swarms. Crucially, the graph representation facilitates automatic optimization on two levels. First, at the node level, since the majority of nodes in the graph involve prompting an LLM, prompt optimization methods can be employed. Second, at the edge level, we demonstrate the application of the REINFORCE algorithm <ref type="bibr" target="#b42">(Williams, 1992)</ref> to optimize the potential connections between nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Optimizing LLM Inference and Self-Improvement</head><p>Much of deep learning research is concerned with tuning the learning algorithms, architectures, hyper-parameters, and other aspects of the learning pipeline <ref type="bibr" target="#b34">(Schmidhuber, 2015;</ref><ref type="bibr" target="#b47">Yan et al., 2015)</ref>. Meta-learning attempts to automate large parts of that process <ref type="bibr" target="#b32">(Schmidhuber, 1987;</ref><ref type="bibr" target="#b8">Elsken et al., 2019;</ref><ref type="bibr" target="#b20">Kirsch &amp; Schmidhuber, 2021)</ref>. Similarly, recently, a lot of research and engineering has gone into the prompting and structuring of LLM inference to make better use of LLMs and build better agents. Due to the ability of LLMs to learn in context <ref type="bibr" target="#b2">(Brown et al., 2020;</ref><ref type="bibr" target="#b21">Kirsch et al., 2022)</ref>, one can view this process as configuring learning algorithms.</p><p>The optimization of the inference structure and the prompts can then be viewed as meta-learning in LLMs.</p><p>In the realm of prompt optimization, OPRO <ref type="bibr" target="#b48">(Yang et al., 2023)</ref> generates better prompts through iterative LLM queries using prior solutions and their performance. Prompt-Breeder <ref type="bibr" target="#b9">(Fernando et al., 2023)</ref> implements a mechanism that evolves and self-improves task-specific and metaprompts through mutation and LLM prompting. Related to these works, we self-improve future prompts by prompting LLMs. Similarly to our work, DSPy <ref type="bibr" target="#b18">(Khattab et al., 2023)</ref> implements LLM pipelines as computational graphs with modular LLM queries as nodes, parameterized by prompts and neural network weights. It proposes a two-stage process to optimize the parameters of these nodes. Initially, it generates a set of candidate solutions for each node. Subsequently, it optimizes across the Cartesian product of these candidate solution sets, aiming to identify an effective combination of parameters for the entire graph. To address the combinatorial optimization challenge raised in DSPy, we propose an iterative optimization process. By virtue of decomposing a solution into nodes with expected functions, at each iteration, we improve each node individually, conditioned on the execution history of the graph with the current prompts of each node.</p><p>Regarding the optimization of the inference structure, Dy-LAN <ref type="bibr" target="#b25">(Liu et al., 2023)</ref> uses a fixed heuristic to improve the collaboration of LLM agents by selecting agents and determining the number of communication rounds. In line with previous ideas on self-referential learning <ref type="bibr" target="#b33">(Schmidhuber, 1993;</ref><ref type="bibr" target="#b14">Irie et al., 2022;</ref><ref type="bibr">Kirsch &amp; Schmidhuber, 2022)</ref>, STOP <ref type="bibr" target="#b51">(Zelikman et al., 2023)</ref> optimizes both the prompts and the inference structure together by introducing an initial improver program that is applied to itself to iteratively improve its performance. In our work, we optimize the inference structure by employing RL techniques applied to the potential edges of a given graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This paper introduces GPTSwarm, an open-source framework that constructs language agents from graphs and agent societies from graph compositions. This approach allows for the easy implementation of existing methods from basic node operations and enables automatic optimization of the graph in the form of node-level improvement and edge-level REINFORCE optimization. Our experiments demonstrate the advantages of our language agent graphs and automatic optimization on several benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact Statement</head><p>This paper presents work whose goal is to advance the field of Machine Learning. The societal consequences of our work are multifaceted. On the one hand, it could lead to significant advancements in the efficiency and effectiveness of machine learning systems. On the other hand, the increased capability and automation of LLM agents might raise ethical and employment concerns. As AI systems become more autonomous and powerful, it is crucial to consider their impact on job displacement and the importance of implementing safeguards to prevent biased or unethical AI behaviors. Furthermore, the potential for misuse of advanced AI technologies requires rigorous oversight and the development of ethical guidelines to ensure that these technologies are used responsibly and for the benefit of society as a whole. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Swarm examples</head><p>To facilitate understanding of the concepts presented in this study, we are showing a simple example of a swarm consisting of 3 agents: Tree-of-Thought, Input-Output, and Decision Agents in Figure <ref type="figure" target="#fig_6">7</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Experimental Details</head><p>In our experiments involving multiple agents, we incorporate an additional virtual agent, represented by a single node, to serve as a final decision aggregator. This node is designated as the output node for the composite graph, and its specific implementation varies between different experiments. Common implementations for this node include employing a majority vote and a self-consistency strategy for decision-making. Unless explicitly stated, communication between agents within a composite graph does not include this virtual agent. Additionally, in all our experiments, the potential edge set of a composite graph is defined as all possible node pairs, provided that the nodes in each pair originate from different agents.</p><p>We exclude any edges that would connect the output node of a composite graph to other nodes. Moreover, we employ the Adam <ref type="bibr" target="#b19">(Kingma &amp; Ba, 2014)</ref> optimizer with parameters β 1 = 0.9, β 2 = 0.999 and a variable learning rate in place of the vanilla stochastic gradient accent method described in Alg. 2. Finally, we use the version gpt-4-1106-preview and gpt-3.5-turbo-1106 for LLMs. For the vision-language model utilized in the GAIA experiments, we employed the gpt-4-1106-vision-preview version of GPT-4-Turbo.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1. MMLU</head><p>Statistical information on adversarial rubustness experiments is collected in Table <ref type="table" target="#tab_3">3</ref>. The convergence of the train utility with the baseline for the 3T3A experiment is shown in Figure <ref type="figure" target="#fig_9">9</ref>.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1.1. HYPER-PARAMETERS &amp; PROMPTS</head><p>We use the Adam optimizer with a learning rate of 0.1 to update the logit parameters associated with each potential edge. The prompts that have been used for the adversarial robustness experiments are collected in Table <ref type="table" target="#tab_4">4</ref>. An example of a swarm with 2 truthful and 2 adversarial examples is shown in Figure <ref type="figure" target="#fig_11">10</ref>. Figure <ref type="figure" target="#fig_11">10a</ref> shows all potential edges before optimization. Figure <ref type="figure" target="#fig_11">10b</ref> shows only the edges that were connected after optimization was complete. Note that the disconnected agents and edges are pruned.  In our Mini Crosswords experiments, each node returns one or two solutions-either updated or unchanged-for each received solution. The solutions produced by a node are conditionally independent of each other, given the input solutions of the node. The output node of a composite graph forwards all received solutions without alteration. To ensure integration within the system, we mandate the existence of edges from any agent's output node directly to the composite graph's output node.</p><p>Our TOT agent uses a tree-search strategy across a perfect binary tree with a depth of eight. Instead of constructing a graph of 2 9 − 1 nodes to represent this tree, the search is carried out through a chain of eight branching nodes. Each branching node is designed to generate two solutions from every input solution that it processes, effectively embodying the TOT strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2.2. HYPER-PARAMETERS &amp; PROMPTS</head><p>The candidate word generation prompt and the pruning prompt are adapted from the original TOT work <ref type="bibr" target="#b50">(Yao et al., 2023)</ref> and detailed in Table <ref type="table" target="#tab_5">5</ref>. A clue is defined as a partial filling of the crossword, accompanied by its intended word description and specific position on the board.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3. HumanEval</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3.1. THE NODE OPTIMIZATION METHOD</head><p>For node optimization, we update each node after every four new problem executions. When addressing a new problem q with graph G, executing G(q) produces a program, denoted by s, whose effectiveness is assessed against test examples associated with q. The input-output pairs of the nodes generated during the evaluation of G(q) are classified as positive if s passes the tests and as negative otherwise. We limit each node to include a maximum of four demonstration examples.</p><p>Let n be a node in the graph associated with a computational routine f p n , which returns Python programs, parameterized by demonstration examples p. During an optimization step of n, that is, an application of I as described in Section 2.4, we assess whether to retain existing demonstration examples (p 1 n ) or to augment them with positive examples from the four most recent problems, subsequently randomly selecting up to four unique examples from this pool (denoted as p 2 n ). More specifically, let Z be the set of the last ten inputs of node n received when solving the first-seen problems. We select p i n to update the demonstration examples of n, where i = arg max i∈{1,2} z∈Z 1 z (f p i n n (z, q z )), 1 z determines whether a program passes the unit tests stated in z, and q z is the original graph input associated with z.</p><p>The utility measure for Mini Crosswords experiments is defined as the best state word accuracy, as detailed in Section 3.2. To reduce the variance in gradient estimation with the REINFORCE algorithm, we adjust the utility by subtracting a constant of 0.4. For example, a perfectly completed solution results in a utility of 0.6, while an empty solution yields a utility of −0.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3.2. HYPER-PARAMETERS &amp; PROMPTS</head><p>Table <ref type="table" target="#tab_6">6</ref> shows the prompts used in our experiments following the principle of ReAct <ref type="bibr" target="#b49">(Yao et al., 2022)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4.2. HYPER-PARAMETERS &amp; PROMPTS</head><p>We use GPT-4-Turbo for the experiments and design different node operations to solve the GAIA tasks. Table <ref type="table">7 and Table 8</ref> show the prompts used in our experiments. {suggestions generated by previous Reflection nodes} Given the current status, list all possible answers for unfilled or changed words, and your confidence levels (certain/high/medium/low), using the format "h1. apple (medium)". Use "certain" cautiously and only when you are 100% sure this is the correct word. You can list more then one possible answer for each word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pruning prompt</head><p>Evaluate if there exists a five letter word of some meaning that fit some letter constraints (sure/maybe/impossible). Incorrect; to injure: w o g The letter constraint is: 5 letters, letter 1 is w, letter 3 is o, letter 5 is g. Some possible words that mean "Incorrect; to injure": wrong (w r o n g): 5 letters, letter 1 is w, letter 3 is o, letter 5 is g. fit! sure A person with an all-consuming enthusiasm, such as for computers or anime: u The letter constraint is: 5 letters, letter 5 is u. Some possible words that mean "A person with an all-consuming enthusiasm, such as for computers or anime": geek (g e e k): 4 letters, not 5 otaku (o t a k u): 5 letters, letter 5 is u sure Dewy; roscid: r l The letter constraint is: 5 letters, letter 1 is r, letter 5 is l. Some possible words that mean "Dewy; roscid": moist (m o i s t): 5 letters, letter 1 is m, not r humid (h u m i d): 5 letters, letter 1 is h, not r I cannot think of any words now. Only 2 letters are constrained, it is still likely maybe A woodland: l d e The letter constraint is: 5 letters, letter 2 is l, letter 4 is d, letter 5 is e. Some possible words that mean "A woodland": forest (f o r e s t): 6 letters, not 5 woods (w o o d s): 5 letters, letter 2 is o, not l grove (g r o v e): 5 letters, letter 2 is r, not l I cannot think of any words now. 3 letters are constrained, and l d e seems a common pattern maybe An inn: d w f The letter constraint is: 5 letters, letter 2 is d, letter 4 is w, letter 5 is f. Some possible words that mean "An inn": hotel (h o t e l): 5 letters, letter 2 is o, not d lodge (l o d g e): 5 letters, letter 2 is o, not d I cannot think of any words now. 3 letters are constrained, and it is extremely unlikely to have a word with pattern d w f to mean "An inn" impossible Chance; a parasitic worm; a fish: w r a k The letter constraint is: 5 letters, letter 1 is w, letter 2 is r, letter 3 is a, letter 4 is k. Some possible words that mean "Chance; a parasitic worm; a fish": fluke (f l u k e): 5 letters, letter 1 is f, not w I cannot think of any words now. 4 letters are constrained, and it is extremely unlikely to have a word with pattern w r a k to mean "Chance; a parasitic worm; a fish" impossible {clue} Suggestion Prompt You are playing a 5 x 5 mini crossword, where each word should have exactly 5 letters. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure1. GPTSwarm is a framework that represents agents as graphs. In this framework, each node represents an operation (e.g., LLM inference or tool use). An agent is a graph composed of these nodes. An edge between two agent graphs characterizes a communication channel; each agent collaborates with others through different channels. When connected, multiple agents form a composite graph with a certain orchestration topology. This graph representation lends itself to optimization of nodes and edges via prompting and evolutionary or reinforcement learning techniques.</figDesc><graphic coords="2,240.22,195.76,69.63,69.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Score recovery through edge optimization. "T" denotes truthful and "A" adversarial agents, e.g., a 3T3A swarm has 3 of each. Ablation studies include a "full graph" and random graphs sampled according to distribution D0.5. The dashed line corresponds to the direct answer baseline.</figDesc><graphic coords="5,313.90,137.17,82.34,66.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Visualizing the evolution of the probability distribution during optimization in adjacency-like matrices. In this figure, we show the probability parameters (one corresponds to an edge) in an adjacency-like matrix for iterations 0, 2, 4, 6, 8, and 10 of optimizing the objective for the Mini Crosswords task.We observe that the parameters first change chaotically. However, after iteration 6, the parameters change almost monotonically.</figDesc><graphic coords="5,459.81,137.17,82.34,66.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure4. Edge optimization on the Mini Crosswords dataset improves over standard methods The baseline methods are evaluated with GPT-3.5-Turbo. The optimized final distribution outperforms several baselines. When evaluating the already optimized edge distribution with GPT-4-Turbo, we achieve better results compared to the previous state-of-the-art method (Tree of Thought).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure5. Solving a wide range of tasks requires many different tools. The GAIA benchmark<ref type="bibr" target="#b26">(Mialon et al., 2023)</ref> tests for many of these capabilities by including questions that require several of these tools for successful completion.</figDesc><graphic coords="7,125.42,96.73,96.65,97.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. The cLass diagram of the GPTSwarm framework.</figDesc><graphic coords="13,60.30,199.37,476.29,360.51" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. A simple example of a swarm consisting of one Tree-of-Thought, one Input-Output, and the Decision agent.</figDesc><graphic coords="14,104.04,122.46,388.80,291.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Different agents or swarms implemented by GPTSwarm.</figDesc><graphic coords="15,228.53,486.14,114.33,114.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 .</head><label>9</label><figDesc>Figure9. The training score during the optimization of the adversarial swarm (3T3A) on MMLU. We apply smoothing with an unbiased exponential moving average and the smoothness factor of 0.97.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>(a) An non-optimized swarm with 2 truthful agents and 2 adversarial agents. Dotted arrows depict potential edges. (b) An optimized swarm with realized edges.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. A 2T2A swarm before (a) and after (b) optimization</figDesc><graphic coords="17,208.53,518.27,179.81,157.99" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>agents and swarms. Representative agents and swarms are visualized in Figure8.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>; Choose "Best" refers to the LLM's favorite answer among the different agents' answers. All agents and swarms are implemented using our GPTSwarm framework.</figDesc><table><row><cell>Agent or Swarm</cell><cell>DA</cell><cell>GQ</cell><cell>WS</cell><cell>FA</cell><cell>CA</cell><cell>Decision Strategy</cell><cell>Accuracy</cell><cell>Best</cell><cell>Duration (s)</cell></row><row><cell>(A) Agent: IO</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>N/A</cell><cell>16.60±3.02</cell><cell>20.75%</cell><cell>∼13.37</cell></row><row><cell>(B) Agent: COTweb</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>N/A</cell><cell>18.87±2.67</cell><cell>22.64%</cell><cell>∼60.90</cell></row><row><cell>(C) Agent: COTFA</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>N/A</cell><cell>25.28±3.50</cell><cell>30.18%</cell><cell>∼56.42</cell></row><row><cell>(D) Agent: TOT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>N/A</cell><cell>25.66±3.50</cell><cell>30.18%</cell><cell>∼71.31</cell></row><row><cell>(E) Swarm(3×IO)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Choose "Best"</cell><cell>15.85±0.92</cell><cell>18.87%</cell><cell>∼45.65</cell></row><row><cell>(F) Swarm(3×COT)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Choose "Best"</cell><cell>27.17±3.29</cell><cell>32.08%</cell><cell>∼152.89</cell></row><row><cell>(G) Swarm(3×TOT)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Choose "Best"</cell><cell>30.18±4.30</cell><cell>35.85%</cell><cell>∼198.50</cell></row><row><cell>(H) Swarm(3×IO)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Self-Consistency</cell><cell>18.11±3.07</cell><cell>22.64%</cell><cell>∼45.70</cell></row><row><cell>(I) Swarm(3×COT)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Self-Consistency</cell><cell>27.17±4.06</cell><cell>32.08%</cell><cell>∼150.26</cell></row><row><cell>(J) Swarm(3×TOT)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Self-Consistency</cell><cell>28.30±3.38</cell><cell>32.08%</cell><cell>∼181.15</cell></row><row><cell>(K) Swarm(5×TOT)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Self-Consistency</cell><cell>29.06±2.56</cell><cell>32.08%</cell><cell>∼291.07</cell></row><row><cell>(L) Swarm(7×TOT)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Self-Consistency</cell><cell>30.56±3.25</cell><cell>35.85%</cell><cell>∼414.89</cell></row><row><cell>(M) Human</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>94%</cell><cell>-</cell><cell>∼422.26</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Stats for the adversarial experiments. #Nodes means the number of nodes in the swarm excluding the final decision node. #Potential edges is the total number of edges that are optimized and potentially realized. The optimization time is measured as the wall clock time. #LLM inferences is the total number of LLM queries made during the optimization cycle when graph pruning is turned off.</figDesc><table><row><cell>Swarm configuration</cell><cell>#Nodes</cell><cell>#Potential edges</cell><cell>Optimization time, mins</cell></row><row><cell>1 Trustful Agent + 1 Adversarial Agent</cell><cell>2</cell><cell>4</cell><cell>9</cell></row><row><cell>3 Trustful Agents + 3 Adversarial Agents</cell><cell>6</cell><cell>36</cell><cell>23</cell></row><row><cell>5 Trustful Agents + 5 Adversarial Agents</cell><cell>10</cell><cell>100</cell><cell>58</cell></row><row><cell>7 Trustful Agents + 7 Adversarial Agents</cell><cell>14</cell><cell>196</cell><cell>95</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Prompts for the Adversarial experiments on MMLU.Prompt purpose PromptSystem prompt You are a knowledgeable expert in question answering. I will ask you a question. I will also give you 4 answers enumerated as A, B, C and D. Only one answer out of the offered 4 is correct. You must choose the correct answer to the question. Your response must be one of the 4 letters:</figDesc><table><row><cell></cell><cell>A, B, C or D, corresponding to the correct answer. Only one letter (A, B, C or D) is allowed in</cell></row><row><cell></cell><cell>your answer.</cell></row><row><cell>Direct answer template</cell><cell>{question}</cell></row><row><cell>Adversarial answer tem-</cell><cell>Answer a lie to the following question: {question}.</cell></row><row><cell>plate</cell><cell></cell></row></table><note>Question template {open-ended question}. Option A: {option A}, Option B: {option B}, Option C: {option C}, Option D: {option D}. D.1.2. ADVERSARIAL SWARM OPTIMIZATION CASE STUDY</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>Prompts for the Mini Crosswords Experiments.</figDesc><table><row><cell cols="2">Prompt purpose</cell><cell>Prompt</cell></row><row><cell>Candidate</cell><cell>words</cell><cell>Let's play a 5 x 5 mini crossword, where each word should have exactly 5 letters.</cell></row><row><cell cols="2">generation prompt</cell><cell>{current board status}</cell></row><row><cell></cell><cell></cell><cell>Unfilled:</cell></row><row><cell></cell><cell></cell><cell>{Unfilled clues}</cell></row><row><cell></cell><cell></cell><cell>Filled:</cell></row><row><cell></cell><cell></cell><cell>{filled clues}</cell></row><row><cell></cell><cell></cell><cell>Changed:</cell></row><row><cell></cell><cell></cell><cell>{Changed clues}</cell></row><row><cell></cell><cell></cell><cell>Suggestions:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 .</head><label>6</label><figDesc>Given the current status: {current board status } The target words are classified as Impossible Words, Correct Words, and Incorrect Words. Respond at most five sentences, one sentence per line. Do not include the phrase "next time" in your response. Prompts for the Node Optimization experiments on HumanEval.Prompt purpose PromptSystem prompt You are an AI that only responds with only Python code.CodeWritingYou will be given a function signature and its docstring by the user. Write your full implementation (restate the function signature). Use a Python code block to write your response. For example: "'python print('Hello world!') "' {Demonstrations} {problem statement} CodeWriting (ReAct) You will be given a function signature and its docstring by the user. Write your full implementation (restate the function signature). Use a Python code block to write your response. For example: "'python print('Hello world!') "' {Demonstrations} Here is an unsuccessful attempt to solve the following question:</figDesc><table><row><cell>---</cell></row><row><cell>Impossible Words:</cell></row><row><cell>{impossible clues}</cell></row><row><cell>Correct Words:</cell></row><row><cell>{correct clues }</cell></row><row><cell>Incorrect Words:</cell></row><row><cell>{incorrect clues }</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0">https://www.goobix.com/crosswords</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1">We are limiting our evaluation to a single graph distribution due to the high cost associated with API calls for this type of evaluation.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2">We use SearchAPI (https://serpapi.com) in the experiments</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3">https://twitter.com/lilianweng/status/1673535600690102273</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Contributions</head><p>Mingchen initiated the project and conceived the initial idea, led the development of the codebase, conducted GAIA &amp; HumanEval experiments, drafted the initial manuscript, and created most of the visualizations. Wenyi discussed the core ideas with Mingchen, contributed to the codebase, conducted Mini CrossWords &amp; HumanEval experiments, and drafted the initial manuscript. Louis reviewed and polished the paper, extensively rewrote the introduction, and coordinated team meetings. Francesco reviewed and polished the paper, significantly revising the methods section. Furthermore, Louis and Francesco discussed and formalized various techniques for graph optimization. As the senior engineering lead, Dmitrii advised and made significant revisions to the codebase, conducted the MMLU experiments, and contributed to the visualizations. Juergen, as mentor and advisor, offered guidance and support throughout the project's progression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The GPTSwarm Framework</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. The Vision</head><p>Many recent language agents are described as compositions of components of different functionalities <ref type="bibr" target="#b39">(Wang et al., 2023)</ref>. A popular tweet states: "agent = LLM + memory + planning skills + tool use." 4 Such additive formulations highlight individual components, but fail to address the essential aspect of component integration. GPTswarm's computational graph formulation, however, precisely focuses on integration through edge optimization, to learn improved recommendations of agent orchestration and precise agent routing. This will become increasingly relevant as swarm size increases to millions or billions of agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Class Diagram</head><p>The GPTSwarm framework is developed using Python and PyTorch. Its class diagram is illustrated in Figure <ref type="figure">6</ref>.</p><p>On the graph level, Node, Graph, and CompositeGraph are directly implemented as classes. Graph edges are implicitly stored as an adjacency list within each Node. Functionally, the framework distinguishes between Agents and Operations through various classes, such as DirectAnswer and WebSearch for operations, and IO and TOT for agents. To encapsulate the abstraction of an external LLM, we introduce an interface named after it. The primary implementation of this interface is a lightweight wrapper around the OpenAI API. To facilitate dataset integration for optimization and evaluation, we provide implementations for two interfaces: Dataset and PromptSet. The Dataset interface is designed to load benchmark datasets like GAIA and MMLU, while the PromptSet customizes node behavior for a specific Dataset. The Evaluator class manages the optimization processes for both edges and nodes.</p><p>The framework is highly customizable, allowing users to add more LLM backends, Dataset and PromptSet combinations, Agents, and Nodes as needed. Additionally, the framework makes extensive use of asynchronous computations for task parallelism, leveraging Python's async-await syntax. Read each candidate answer thoroughly and assess its relevance and accuracy about the question.</p><p>3. Choose the answer that most accurately and completely addresses the question. 4. Ignore the candidate answers if they do not give a direct answer, for example, using 'unable to ...', 'as an AI ...'. "5.</p><p>Copy the chosen answer exactly as it is presented, maintaining its original format. 6. Adhere to the constraints: {constraint}.</p><p>Note: If none of the answers fully meet the question's criteria, select the one closest to fulfilling them.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Akkaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Aleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Altenschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Anadkat</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.08774</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Graph of thoughts: Solving elaborate problems with large language models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Besta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Blach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kubicek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gerstenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gianinazzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gajda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Podstawski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Niewiadomski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nyczyk</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.09687</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
				<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">H</forename><surname>Chase</surname></persName>
		</author>
		<author>
			<persName><surname>Langchain</surname></persName>
		</author>
		<ptr target="https://github.com/hwchase17/langchain" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Autoagents: A framework for automatic agent generation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sesay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">F</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.17288</idno>
		<imprint>
			<date type="published" when="2023">2023a</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tworek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P D O</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Brockman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.03374</idno>
		<title level="m">Evaluating large language models trained on code</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors in agents</title>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-M</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.10848</idno>
		<imprint>
			<date type="published" when="2023">2023b</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-P</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><surname>Rlprompt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.12548</idno>
		<title level="m">Optimizing discrete text prompts with reinforcement learning</title>
				<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural architecture search: A survey</title>
		<author>
			<persName><forename type="first">T</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="1997">1997-2017, 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Promptbreeder: Self-referential self-improvement via prompt evolution</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Banarse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Michalewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rocktäschel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.16797</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">S</forename><surname>Gravitas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">Auto-gpt. GitHub repository</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Aligning ai with shared human values</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Critch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
				<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2021">2021a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Measuring massive multitask language understanding</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Steinhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
				<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2021">2021b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K S</forename><surname>Yau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.00352</idno>
		<title level="m">Meta programming for multi-agent collaborative framework</title>
				<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A modern self-referential weight matrix that learns to modify itself</title>
		<author>
			<persName><forename type="first">K</forename><surname>Irie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Schlag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Csordás</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
				<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="9660" to="9677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Joint Publications Research Service [available from the Clearinghouse for Federal Scientific and Technical Information</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ivakhnenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Lapa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Engineering</forename></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">U L I S O E</forename></persName>
		</author>
		<ptr target="https://books.google.com.sa/books?id=l38DHQAACAAJ" />
	</analytic>
	<monogr>
		<title level="j">JPRS</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<date type="published" when="1965">1965</date>
		</imprint>
	</monogr>
	<note>Cybernetic Predicting Devices</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The group method of data handling, a rival of the method of stochastic approximation</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Ivakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soviet Automatic Control</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="43" to="55" />
			<date type="published" when="1968">1968</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Swarm intelligence. In Handbook of natureinspired and innovative computing: integrating classical models with emerging technologies</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kennedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="187" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Khattab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singhvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maheshwari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Santhanam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vardhamanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Haq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Moazam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.03714</idno>
		<title level="m">Compiling declarative language model calls into self-improving pipelines</title>
				<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">A method for stochastic optimization</title>
				<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Eliminating meta optimization through self-referential meta learning</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kirsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kirsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.14392</idno>
	</analytic>
	<monogr>
		<title level="m">and First Conference on Automated Machine Learning (Workshop)</title>
				<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Advances in Neural Information Processing Systems</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">General-purpose in-context learning by meta-learning transformers</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kirsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.04458</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Large language models are zero-shot reasoners. Advances in neural information processing systems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Iwasawa</surname></persName>
		</author>
		<ptr target="https://github.com/langchain-ai/langgraph" />
		<imprint>
			<date type="published" when="2022">2022. 2024</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="22199" to="22213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A A K</forename><surname>Hammoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Itani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Khizbullin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName><surname>Camel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.17760</idno>
		<title level="m">Communicative agents for&quot; mind&quot; exploration of large scale language model society</title>
				<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Llamaindex</surname></persName>
		</author>
		<ptr target="https://github.com/jerryjliu/llama_index" />
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Dynamic llm-agent network: An llm-agent collaboration framework with agent team optimization</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.02170</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Mialon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fourrier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Swift</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Scialom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2311.12983</idno>
		<title level="m">Gaia: a benchmark for general ai assistants</title>
				<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Society of mind</title>
		<author>
			<persName><forename type="first">M</forename><surname>Minsky</surname></persName>
		</author>
		<ptr target="https://github.com/yoheinakajima/babyagi" />
		<imprint>
			<date type="published" when="1988">1988. 2023</date>
			<publisher>Simon and Schuster</publisher>
			<pubPlace>Nakajima, Y</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Hierarchical self-organization of non-cooperating individuals</title>
		<author>
			<persName><forename type="first">T</forename><surname>Nepusz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Vicsek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Plos one</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">e81449</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Generative agents: Interactive simulacra of human behavior</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>O'brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology</title>
				<meeting>the 36th Annual ACM Symposium on User Interface Software and Technology</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Automatic prompt optimization with&quot; gradient descent&quot; and beam search</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pryzant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Iter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zeng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.03495</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.07924</idno>
		<title level="m">Communicative agents for software development</title>
				<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Evolutionary principles in self-referential learning, or on learning how to learn: the meta-meta-... hook</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
		</imprint>
		<respStmt>
			<orgName>Technische Universität München</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A &apos;self-referential&apos;weight matrix</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICANN&apos;93: Proceedings of the International Conference on Artificial Neural Networks Amsterdam, The Netherlands 13</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1993">16 September 1993 3. 1993</date>
			<biblScope unit="page" from="446" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep learning in neural networks: An overview</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="85" to="117" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Sel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Al-Tawaha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Khattar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2308.10379</idno>
		<title level="m">Algorithm of thoughts: Enhancing exploration of ideas in large language models</title>
				<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Reflexion: Language agents with verbal reinforcement learning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Shinn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Cassano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Labash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gopinath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.11366</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">14</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title/>
		<author>
			<persName><surname>Torantulino</surname></persName>
		</author>
		<ptr target="https://github.com/Significant-Gravitas/Auto-GPT" />
	</analytic>
	<monogr>
		<title level="j">Auto-gpt</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">D&apos;ya like dags? a survey on structure learning and causal discovery</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Vowels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Camgoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bowden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.11432</idno>
		<title level="m">A survey on large language model based autonomous agents</title>
				<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Self-consistency improves chain of thought reasoning in language models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chowdhery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.11171</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Chain-of-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24824" to="24837" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="229" to="256" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Autogen: Enabling next-gen llm applications via multi-agent conversation framework</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2308.08155</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Xagent: An autonomous agent for complex task solving</title>
		<author>
			<persName><forename type="first">Xagent</forename><surname>Team</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.07864</idno>
		<title level="m">The rise and potential of large language model based agents: A survey</title>
				<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Openagents: An open platform for language agents in the wild</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.10634</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Yoshua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2309.03409</idno>
		<title level="m">Large language models as optimizers</title>
				<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.03629</idno>
		<title level="m">Synergizing reasoning and acting in language models</title>
				<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Tree of thoughts: Deliberate problem solving with large language models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Narasimhan</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=5Xc1ecxO1h" />
	</analytic>
	<monogr>
		<title level="m">Thirtyseventh Conference on Neural Information Processing Systems</title>
				<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Selftaught optimizer (stop): Recursively self-improving code generation</title>
		<author>
			<persName><forename type="first">E</forename><surname>Zelikman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lorch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mackey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Kalai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.02304</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Socratic models: Composing zero-shot multimodal reasoning with language</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Attarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Ichter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Choromanski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Welker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Purohit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ryoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sindhwani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.00598</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Zhuge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Faccio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Ashley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Csordás</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A A K</forename><surname>Hammoud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Herrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Irie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.17066</idno>
		<title level="m">Mindstorms in natural language-based societies of mind</title>
				<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
